{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af70780",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "---\n",
    "\n",
    "The idea for the following project came from a [Medium post](https://medium.com/@dmytrosazonov/how-to-predict-stock-market-using-google-tensorflow-and-lstm-neural-network-81ccc41a22a8). We improve the Medium's code adding new models and new analysis. To do that, the group used as tools the [ChatGPT](https://chat.openai.com/) optimizations and the [Aur√©lien Geron's public notebooks](https://github.com/ageron/handson-ml2/blob/master/15_processing_sequences_using_rnns_and_cnns.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3824d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import time as tm\n",
    "\n",
    "# AI\n",
    "import keras\n",
    "\n",
    "# Graphics library\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Data preparation\n",
    "from yahoo_fin import stock_info as yf\n",
    "\n",
    "from utils import (\n",
    "    last_time_step_mse,\n",
    "    plot_learning_curves,\n",
    "    plot_multiple_forecasts,\n",
    "    plot_series,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52df48a7",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "--- \n",
    "\n",
    "#### Load Data From Yahoo API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5038bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  \n",
    "\n",
    "ANALYZED_YEARS = 5 #periodo de analise\n",
    "STOCK = \"GOOGL\" #acao a ser analisada\n",
    "INTERVAL = \"1d\" #intervalo de tempo\n",
    "N_STEPS = 22  # 22 dias uteis por mes\n",
    "EPOCHS = 50 #epocas de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19a2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading data\n",
    "init_df = yf.get_data(\n",
    "    STOCK,\n",
    "    start_date=(dt.date.today() - dt.timedelta(days=365 * ANALYZED_YEARS)).strftime(\n",
    "        \"%Y-%m-%d\"\n",
    "    ),\n",
    "    end_date=tm.strftime(\"%Y-%m-%d\"),\n",
    "    interval=INTERVAL,\n",
    ")\n",
    "init_df.to_csv(f\"./data/raw/{STOCK}_{ANALYZED_YEARS}Y_{INTERVAL}.csv\") #salvando dados brutos\n",
    "init_df.head() #mostrando os 5 primeiros registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e9889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removendo colunas nao utilizadas\n",
    "init_df.drop([\"open\", \"high\", \"low\", \"adjclose\", \"ticker\", \"volume\"], axis=1, inplace=True) \n",
    "\n",
    "init_df[\"date\"] = init_df.index #criando coluna de data\n",
    "init_df.reset_index(drop=True, inplace=True) #resetando index\n",
    "\n",
    "# Mudando a escala dos dados para 0-1\n",
    "scaler = MinMaxScaler()\n",
    "init_df[\"close_norm\"] = scaler.fit_transform(\n",
    "    np.expand_dims(init_df[\"close\"].values, axis=1))\n",
    "\n",
    "init_df.to_csv(f\"./data/processed/{STOCK}_{ANALYZED_YEARS}Y_{INTERVAL}.csv\") #salvando dados processados\n",
    "\n",
    "# Salvando os dados normalizados\n",
    "np.save(\n",
    "    f\"./data/processed/{STOCK}_{ANALYZED_YEARS}Y_{INTERVAL}_norm\", init_df[\"close_norm\"])\n",
    "\n",
    "init_df.head() #mostrando os 5 primeiros registros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90de5d31",
   "metadata": {},
   "source": [
    "#### Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847f7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando o grafico de preco de fechamento\n",
    "plt.style.use(style=\"ggplot\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot(init_df[\"date\"], init_df[\"close\"])\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel(\"price\")\n",
    "plt.legend([f\"Actual price for {STOCK}\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16738254",
   "metadata": {},
   "source": [
    "#### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa8d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(f\"./data/processed/{STOCK}_{ANALYZED_YEARS}Y_{INTERVAL}_norm.npy\") #carregando dados normalizados\n",
    "\n",
    "data = np.reshape(data[data.size % N_STEPS :], (data.size // N_STEPS, N_STEPS, 1)) #reorganizando dados para o formato (n, 22, 1) \n",
    "\n",
    "# Dividindo os dados em treino e teste (80% e 20%)\n",
    "X_train, y_train = (\n",
    "    data[: int(data.shape[0] * 0.8), : N_STEPS - 1],\n",
    "    data[: int(data.shape[0] * 0.8), -1],\n",
    ")\n",
    "X_test, y_test = (\n",
    "    data[int(data.shape[0] * 0.8):, : N_STEPS - 1],\n",
    "    data[int(data.shape[0] * 0.8):, -1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010db62b",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "---\n",
    "\n",
    "#### Naive Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = X_test[:, -1] #pegando o ultimo valor de cada sequencia de teste\n",
    "np.mean(keras.losses.mean_squared_error(y_pred, y_test)) #calculando o erro medio quadrado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd3b316",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb17fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) \n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Criando o modelo de regressao linear com keras\n",
    "model = keras.models.Sequential(\n",
    "    [keras.layers.Flatten(input_shape=[N_STEPS - 1, 1]), keras.layers.Dense(1)]\n",
    ")\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\") #compilando o modelo com o otimizador adam e a funcao de perda mse\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, validation_data=(X_test, y_test)) #treinando o modelo com os dados de treino e validando com os dados de teste \n",
    "model.save(f\"./models/LR_{STOCK}_{ANALYZED_YEARS}Y_{INTERVAL}-{N_STEPS}timeSteps\") #salvando o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ffb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test) #avaliando o modelo com os dados de teste\n",
    "\n",
    "#plotando as curvas de treinamento e validacao\n",
    "plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705d32e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test) #fazendo a predicao com os dados de teste\n",
    "\n",
    "#plotando o grafico de comparacao entre os dados de teste e a predicao\n",
    "plot_series(scaler.inverse_transform([X_test[0, :,0]])[0], scaler.inverse_transform(np.array([[y_test[0,0]]])), scaler.inverse_transform(np.array([[y_pred[0,0]]])), n_steps=N_STEPS)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189a099e",
   "metadata": {},
   "source": [
    "#### Deep RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5cf18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEEP RNN\n",
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "        keras.layers.SimpleRNN(20),\n",
    "        keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, validation_data=(X_test, y_test))\n",
    "model.save(f\"./models/RNN_{STOCK}_{ANALYZED_YEARS}Y_{INTERVAL}-{N_STEPS}timeSteps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b2136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando as curvas de treinamento e validacao\n",
    "plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b05e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo a predicao com os dados de teste e plotando o grafico de comparacao\n",
    "y_pred = model.predict(X_test)\n",
    "plot_series(scaler.inverse_transform([X_test[0, :,0]])[0], scaler.inverse_transform(np.array([[y_test[0,0]]])), scaler.inverse_transform(np.array([[y_pred[0,0]]])), n_steps=N_STEPS)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d68144",
   "metadata": {},
   "source": [
    "### Forecast several time steps ahead\n",
    "\n",
    "---\n",
    "\n",
    "To forecast several time steps ahead, we need a new manipulation data method and robust models with memory cells. Here we can establish a comparison between a LSTM and a GRU model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c718e8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forecasting Several Steps Ahead\n",
    "\n",
    "N_STEPS = 30 #numero de time steps\n",
    "FORECAST_DAYS = 5 #numero de dias para previsao\n",
    "\n",
    "data = np.load(f\"./data/processed/{STOCK}_{ANALYZED_YEARS}Y_{INTERVAL}_norm.npy\") \n",
    "data = np.reshape(data[data.size % N_STEPS :], (data.size // N_STEPS, N_STEPS, 1)) #reorganizando dados para o formato (n, 22, 1)\n",
    "\n",
    "X_train = data[: int(data.shape[0] * 0.8), : N_STEPS - FORECAST_DAYS] \n",
    "X_test = data[int(data.shape[0] * 0.8) :, : N_STEPS - FORECAST_DAYS]\n",
    "\n",
    "Y = np.empty((data.shape[0], N_STEPS - FORECAST_DAYS, FORECAST_DAYS))\n",
    "for step_ahead in range(1, FORECAST_DAYS + 1):\n",
    "    Y[:, :, step_ahead - 1] = data[\n",
    "        :, step_ahead : step_ahead + N_STEPS - FORECAST_DAYS, 0\n",
    "    ]\n",
    "\n",
    "y_train = Y[: int(data.shape[0] * 0.8)]\n",
    "y_test = Y[int(data.shape[0] * 0.8) :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed60c473",
   "metadata": {},
   "source": [
    "#### LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a678bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Criando o modelo de regressao linear com keras para previsao de varios dias\n",
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),\n",
    "        keras.layers.LSTM(20, return_sequences=True),\n",
    "        keras.layers.TimeDistributed(keras.layers.Dense(FORECAST_DAYS)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96cf0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando as curvas de treinamento e validacao \n",
    "model.evaluate(X_test, y_test)\n",
    "plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3fe2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(43)\n",
    "\n",
    "# Fazendo a predicao com os dados de teste e plotando o grafico de comparacao\n",
    "X_new, Y_new = (\n",
    "    data[:, : N_STEPS - FORECAST_DAYS, :],\n",
    "    data[:, N_STEPS - FORECAST_DAYS :, :],\n",
    ")\n",
    "Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]\n",
    "plot_multiple_forecasts(X_new, Y_new, Y_pred, scaler)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e448e",
   "metadata": {},
   "source": [
    "#### GRUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b56619",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.GRU(20, return_sequences=True, input_shape=[None, 1]),\n",
    "        keras.layers.GRU(20, return_sequences=True),\n",
    "        keras.layers.TimeDistributed(keras.layers.Dense(FORECAST_DAYS)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, validation_data=(X_test, y_test))\n",
    "model.save(f\"./models/GRU_{STOCK}_{ANALYZED_YEARS}Y_{INTERVAL}-5daysPrediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a0b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb26c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(43)\n",
    "X_new, Y_new = (\n",
    "    data[:, : N_STEPS - FORECAST_DAYS, :],\n",
    "    data[:, N_STEPS - FORECAST_DAYS :, :],\n",
    ")\n",
    "Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]\n",
    "plot_multiple_forecasts(X_new, Y_new, Y_pred, scaler)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e54c91",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "--- \n",
    "As we can see, some of the tested models didn't work as expected. The Naive Forecasting and the Linear Regression models didn't work well. This happens because the stock market is a non-linear system and this models takes into account only the linear relation between the variables and the target. On the other hand, LSTM and GRU models were better and they can be used to forcaste several time steps ahead but nontheless, still not good enough. Finaly, the Deep RNN is the one that mostly got near the real values. This happens because the RNNs are able to learn the non-linear relations between the variables and the target and make a better prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3258a690",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
